{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  sentiment\n0  the rock is destined to be the 21st century's ...          1\n1  the gorgeously elaborate continuation of \" the...          1\n2                     effective but too-tepid biopic          1\n3  if you sometimes like to go to the movies to h...          1\n4  emerges as something rare , an issue movie tha...          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the rock is destined to be the 21st century's ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the gorgeously elaborate continuation of \" the...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>effective but too-tepid biopic</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>if you sometimes like to go to the movies to h...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>emerges as something rare , an issue movie tha...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = pd.read_csv('pos.csv')\n",
    "neg = pd.read_csv('neg.csv')\n",
    "neg = neg.rename(columns={'0': 'text'})\n",
    "pos = pos.rename(columns={'0': 'text'})\n",
    "df = pd.concat([pos, neg])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Характеристики датасета"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество слов в корпусе 224067\n",
      "Количество документов 10662\n",
      "Медианное количестов слов в документе 20.0\n"
     ]
    }
   ],
   "source": [
    "doc_lenghts = df['text'].str.split().apply(lambda x: len(x))\n",
    "doc_count = df.shape[0]\n",
    "\n",
    "print(f'Количество слов в корпусе {sum(doc_lenghts)}')\n",
    "print(f'Количество документов {doc_count}')\n",
    "print(f'Медианное количестов слов в документе {np.median(doc_lenghts)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(df['text'], df['sentiment'], test_size=0.25, random_state=17)\n",
    "\n",
    "pipelines = [\n",
    "    Pipeline([('ngrams_vectorizer', CountVectorizer(stop_words=stopwords_list, token_pattern=r\"[A-z-']+\", ngram_range=(1, 2))),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('char_ngrams_vectorizer', CountVectorizer(analyzer='char', ngram_range=(3, 8))),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('bag_of_words', CountVectorizer(stop_words=stopwords_list, token_pattern=r\"[A-z-']+\")),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('tfidf_params', TfidfVectorizer(max_df=0.95, min_df=2, stop_words=stopwords_list, token_pattern=r\"[A-z-']+\")),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('tfidf_plain', TfidfVectorizer(stop_words=stopwords_list, token_pattern=\"[A-z-']+\")),\n",
    "              ('bayes', MultinomialNB())])\n",
    "]\n",
    "\n",
    "score = pd.DataFrame(columns=['accuracy', 'precision', 'f1_score', 'recall'])\n",
    "\n",
    "def get_pred_score(pipe,\n",
    "                   xtrain=xtrain, ytrain=ytrain,\n",
    "                   xvalid=xvalid, yvalid=yvalid):\n",
    "    pipe.fit(xtrain, ytrain)\n",
    "    predictions = pipe.predict(xvalid)\n",
    "    row = pd.Series({'accuracy': accuracy_score(yvalid, predictions),\n",
    "                     'precision': precision_score(yvalid, predictions),\n",
    "                     'f1_score': f1_score(yvalid, predictions),\n",
    "                     'recall': recall_score(yvalid, predictions)},\n",
    "                    name=pipe.steps[0][0])\n",
    "\n",
    "    return row\n",
    "\n",
    "for pipe in pipelines:\n",
    "    score = score.append(get_pred_score(pipe))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                        accuracy  precision  f1_score    recall\nngrams_vectorizer       0.767442   0.767737  0.768311  0.768886\nchar_ngrams_vectorizer  0.776444   0.764454  0.782323  0.801047\nbag_of_words            0.769692   0.771600  0.769865  0.768138\ntfidf_params            0.765191   0.770342  0.763952  0.757666\ntfidf_plain             0.768942   0.768429  0.770149  0.771877",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>f1_score</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ngrams_vectorizer</th>\n      <td>0.767442</td>\n      <td>0.767737</td>\n      <td>0.768311</td>\n      <td>0.768886</td>\n    </tr>\n    <tr>\n      <th>char_ngrams_vectorizer</th>\n      <td>0.776444</td>\n      <td>0.764454</td>\n      <td>0.782323</td>\n      <td>0.801047</td>\n    </tr>\n    <tr>\n      <th>bag_of_words</th>\n      <td>0.769692</td>\n      <td>0.771600</td>\n      <td>0.769865</td>\n      <td>0.768138</td>\n    </tr>\n    <tr>\n      <th>tfidf_params</th>\n      <td>0.765191</td>\n      <td>0.770342</td>\n      <td>0.763952</td>\n      <td>0.757666</td>\n    </tr>\n    <tr>\n      <th>tfidf_plain</th>\n      <td>0.768942</td>\n      <td>0.768429</td>\n      <td>0.770149</td>\n      <td>0.771877</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}