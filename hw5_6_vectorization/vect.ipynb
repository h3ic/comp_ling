{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  sentiment\n0  the rock is destined to be the 21st century's ...          1\n1  the gorgeously elaborate continuation of \" the...          1\n2                     effective but too-tepid biopic          1\n3  if you sometimes like to go to the movies to h...          1\n4  emerges as something rare , an issue movie tha...          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the rock is destined to be the 21st century's ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the gorgeously elaborate continuation of \" the...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>effective but too-tepid biopic</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>if you sometimes like to go to the movies to h...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>emerges as something rare , an issue movie tha...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = pd.read_csv('pos.csv')\n",
    "neg = pd.read_csv('neg.csv')\n",
    "neg = neg.rename(columns={'0': 'text'})\n",
    "pos = pos.rename(columns={'0': 'text'})\n",
    "df = pd.concat([pos, neg])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Характеристики датасета"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество слов в корпусе 224067\n",
      "Количество документов 10662\n",
      "Медианное количестов слов в документе 20.0\n"
     ]
    }
   ],
   "source": [
    "doc_lenghts = df['text'].str.split().apply(lambda x: len(x))\n",
    "doc_count = df.shape[0]\n",
    "\n",
    "print(f'Количество слов в корпусе {sum(doc_lenghts)}')\n",
    "print(f'Количество документов {doc_count}')\n",
    "print(f'Медианное количестов слов в документе {np.median(doc_lenghts)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# wnl = WordNetLemmatizer()\n",
    "# df['text'] = df.apply(lambda sent: re_tokenizer.tokenize(sent['text']), axis=1)\n",
    "# df['text'] = df.apply(lambda sent: [token.lower() for token in sent['text'] if len(token) > 2 and token.isalpha()], axis=1)\n",
    "# df['text'] = df.apply(lambda sent: [wnl.lemmatize(word) for word in sent['text']], axis=1)\n",
    "# df['text'] = df.apply(lambda sent: [word for word in sent['text'] if word not in stopwords_list], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(df['text'], df['sentiment'], test_size=0.25, random_state=17)\n",
    "\n",
    "pipelines = [\n",
    "    Pipeline([('ngrams_vectorizer', CountVectorizer(stop_words=stopwords_list, token_pattern=r\"[A-z-']+\", ngram_range=(1, 2))),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('ngrams_vectorizer', CountVectorizer(stop_words=stopwords_list, token_pattern=r\"[A-z-']+\", ngram_range=(1, 3))),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('ngrams_vectorizer', CountVectorizer(stop_words=stopwords_list, token_pattern=r\"[A-z-']+\", ngram_range=(2, 4))),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('char_ngrams_vectorizer', CountVectorizer(analyzer='char', ngram_range=(3, 8))),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('char_ngrams_vectorizer', CountVectorizer(analyzer='char', ngram_range=(2, 5))),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('char_ngrams_vectorizer', CountVectorizer(analyzer='char', ngram_range=(4, 6))),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('bag_of_words', CountVectorizer(stop_words=stopwords_list, token_pattern=r\"[A-z-']+\")),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('tfidf_params', TfidfVectorizer(max_df=0.95, min_df=2, stop_words=stopwords_list, token_pattern=r\"[A-z-']+\")),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('tfidf_params', TfidfVectorizer(max_df=0.96, min_df=3, stop_words=stopwords_list, token_pattern=r\"[A-z-']+\")),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('tfidf_params', TfidfVectorizer(max_df=0.97, min_df=4, stop_words=stopwords_list, token_pattern=r\"[A-z-']+\")),\n",
    "              ('bayes', MultinomialNB())]),\n",
    "    Pipeline([('tfidf_plain', TfidfVectorizer(stop_words=stopwords_list, token_pattern=\"[A-z-']+\")),\n",
    "              ('bayes', MultinomialNB())])\n",
    "]\n",
    "\n",
    "score = pd.DataFrame(columns=['accuracy', 'precision', 'f1_score', 'recall'])\n",
    "\n",
    "def get_pred_score(pipe,\n",
    "                   xtrain=xtrain, ytrain=ytrain,\n",
    "                   xvalid=xvalid, yvalid=yvalid):\n",
    "    pipe.fit(xtrain, ytrain)\n",
    "    predictions = pipe.predict(xvalid)\n",
    "    pipe_name = pipe.steps[0][0] + ' '\n",
    "    if pipe_name in ['ngrams_vectorizer ', 'char_ngrams_vectorizer ']:\n",
    "        pipe_name += 'ngram_range ' + str(pipe.__dict__['steps'][0][1].ngram_range)\n",
    "    if pipe_name in ['tfidf_params ', 'tfidf_plain ']:\n",
    "        pipe_name += 'min_df ' + str(pipe.__dict__['steps'][0][1].min_df) + ' '\n",
    "        pipe_name += 'max_df ' + str(pipe.__dict__['steps'][0][1].max_df)\n",
    "\n",
    "    row = pd.Series({'accuracy': accuracy_score(yvalid, predictions),\n",
    "                     'precision': precision_score(yvalid, predictions),\n",
    "                     'f1_score': f1_score(yvalid, predictions),\n",
    "                     'recall': recall_score(yvalid, predictions)},\n",
    "                     name=pipe_name)\n",
    "\n",
    "    return row\n",
    "\n",
    "for pipe in pipelines:\n",
    "    score = score.append(get_pred_score(pipe))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Разные гиперпараметры не дают существенного прироста эффективности модели"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           accuracy  precision  f1_score  \\\nngrams_vectorizer ngram_range (1, 2)       0.767442   0.767737  0.768311   \nngrams_vectorizer ngram_range (1, 3)       0.768567   0.768657  0.769518   \nngrams_vectorizer ngram_range (2, 4)       0.609527   0.684539  0.513324   \nchar_ngrams_vectorizer ngram_range (3, 8)  0.776444   0.764454  0.782323   \nchar_ngrams_vectorizer ngram_range (2, 5)  0.764441   0.760470  0.767235   \nchar_ngrams_vectorizer ngram_range (4, 6)  0.779820   0.773723  0.783155   \nbag_of_words                               0.769692   0.771600  0.769865   \ntfidf_params min_df 2 max_df 0.95          0.765191   0.770342  0.763952   \ntfidf_params min_df 3 max_df 0.96          0.767817   0.771558  0.767206   \ntfidf_params min_df 4 max_df 0.97          0.758815   0.764885  0.757083   \ntfidf_plain min_df 1 max_df 1.0            0.768942   0.768429  0.770149   \n\n                                             recall  \nngrams_vectorizer ngram_range (1, 2)       0.768886  \nngrams_vectorizer ngram_range (1, 3)       0.770381  \nngrams_vectorizer ngram_range (2, 4)       0.410621  \nchar_ngrams_vectorizer ngram_range (3, 8)  0.801047  \nchar_ngrams_vectorizer ngram_range (2, 5)  0.774121  \nchar_ngrams_vectorizer ngram_range (4, 6)  0.792820  \nbag_of_words                               0.768138  \ntfidf_params min_df 2 max_df 0.95          0.757666  \ntfidf_params min_df 3 max_df 0.96          0.762902  \ntfidf_params min_df 4 max_df 0.97          0.749439  \ntfidf_plain min_df 1 max_df 1.0            0.771877  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>f1_score</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ngrams_vectorizer ngram_range (1, 2)</th>\n      <td>0.767442</td>\n      <td>0.767737</td>\n      <td>0.768311</td>\n      <td>0.768886</td>\n    </tr>\n    <tr>\n      <th>ngrams_vectorizer ngram_range (1, 3)</th>\n      <td>0.768567</td>\n      <td>0.768657</td>\n      <td>0.769518</td>\n      <td>0.770381</td>\n    </tr>\n    <tr>\n      <th>ngrams_vectorizer ngram_range (2, 4)</th>\n      <td>0.609527</td>\n      <td>0.684539</td>\n      <td>0.513324</td>\n      <td>0.410621</td>\n    </tr>\n    <tr>\n      <th>char_ngrams_vectorizer ngram_range (3, 8)</th>\n      <td>0.776444</td>\n      <td>0.764454</td>\n      <td>0.782323</td>\n      <td>0.801047</td>\n    </tr>\n    <tr>\n      <th>char_ngrams_vectorizer ngram_range (2, 5)</th>\n      <td>0.764441</td>\n      <td>0.760470</td>\n      <td>0.767235</td>\n      <td>0.774121</td>\n    </tr>\n    <tr>\n      <th>char_ngrams_vectorizer ngram_range (4, 6)</th>\n      <td>0.779820</td>\n      <td>0.773723</td>\n      <td>0.783155</td>\n      <td>0.792820</td>\n    </tr>\n    <tr>\n      <th>bag_of_words</th>\n      <td>0.769692</td>\n      <td>0.771600</td>\n      <td>0.769865</td>\n      <td>0.768138</td>\n    </tr>\n    <tr>\n      <th>tfidf_params min_df 2 max_df 0.95</th>\n      <td>0.765191</td>\n      <td>0.770342</td>\n      <td>0.763952</td>\n      <td>0.757666</td>\n    </tr>\n    <tr>\n      <th>tfidf_params min_df 3 max_df 0.96</th>\n      <td>0.767817</td>\n      <td>0.771558</td>\n      <td>0.767206</td>\n      <td>0.762902</td>\n    </tr>\n    <tr>\n      <th>tfidf_params min_df 4 max_df 0.97</th>\n      <td>0.758815</td>\n      <td>0.764885</td>\n      <td>0.757083</td>\n      <td>0.749439</td>\n    </tr>\n    <tr>\n      <th>tfidf_plain min_df 1 max_df 1.0</th>\n      <td>0.768942</td>\n      <td>0.768429</td>\n      <td>0.770149</td>\n      <td>0.771877</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}